# PromptDev configuration example with PydanticAI Evals
# Demonstrates the new pydantic_evals integration

description: "Calendar event summary evaluation using PydanticAI pydantic_evals"

prompts:
  - file://./prompts/calendar_event_summary.yaml

providers:
  - id: "pydantic-ai:ollama-llama3.2"
    model: "ollama:llama3.2:3b-instruct-q8_0"
    config:
      temperature: 0.0
      base_url: "http://localhost:11434/v1"
  - id: "pydantic-ai:openai"
    model: "openai:gpt-4"
    config:
      temperature: 0.0

default_test:
  assert:
    - type: "json_schema"
      ref: "#/assertion_templates/containsValidJSONSchema"
    - type: "llm_judge"
      rubric: "Evaluate if the calendar event summary accurately extracts the person's name, event type, and out-of-office status from the input text. The output should be well-structured JSON."
      model: "openai:gpt-4"

tests:
  - file: "file://./datasets/calendar_events.jsonl"

assertion_templates:
  containsValidJSONSchema:
    type: "json_schema"
    value:
      $ref: "#/schemas/calendarEventSummarySchema"
  semanticAccuracy:
    type: "llm_judge"
    rubric: "Assess whether the extracted information is semantically correct and complete based on the input text"
    model: "openai:gpt-4"
  outputFormat:
    type: "is_instance"
    value: "str"

schemas:
  calendarEventSummarySchema:
    type: "object"
    properties:
      out_of_office:
        description: "Whether the event is an out of office event"
        type: "boolean"
      name:
        description: "The name of the person who is out of office"
        type: "string"
      event_type:
        description: "The type of the event"
        type: "string"
    required:
      - "out_of_office"
      - "name"
      - "event_type"
    title: "Calendar event summary"

display:
  include: ["test_name", "provider_id", "score", "passed", "output"]
  verbose: false

cache:
  enabled: false
